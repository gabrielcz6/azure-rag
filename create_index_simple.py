import os
import openai
import time
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import AzureSearch
from langchain.document_loaders import CSVLoader
from langchain.text_splitter import CharacterTextSplitter
from dotenv import load_dotenv

# Cargar variables de entorno
load_dotenv('.env')

print("ğŸ”§ Configurando OpenAI...")
openai.api_base = os.getenv("OPENAI_API_BASE")
openai.api_key = os.getenv("OPENAI_API_KEY")
openai.api_type = "azure"
openai.api_version = "2023-05-15"

print("ğŸ”§ Configurando embeddings...")
embeddings = OpenAIEmbeddings(deployment="demo-embedding", chunk_size=1)

print("ğŸ”§ Conectando a Azure Cognitive Search...")
acs = AzureSearch(
    azure_search_endpoint=os.getenv('SEARCH_SERVICE_NAME'),
    azure_search_key=os.getenv('SEARCH_API_KEY'),
    index_name=os.getenv('SEARCH_INDEX_NAME'),
    embedding_function=embeddings.embed_query
)

# Buscar el archivo CSV
csv_paths = [
    "wine-ratings.csv",
    "examples/1-setup-application/wine-ratings.csv"
]

csv_file = None
for path in csv_paths:
    if os.path.exists(path):
        csv_file = path
        print(f"ğŸ“„ Archivo CSV encontrado: {path}")
        break

if not csv_file:
    print("âŒ Error: No se encontrÃ³ wine-ratings.csv")
    exit()

print("ğŸ“š Cargando archivo CSV...")
loader = CSVLoader(csv_file, encoding='utf-8')
try:
    documents = loader.load()
    print(f"âœ… Total de documentos en CSV: {len(documents)}")
except UnicodeDecodeError:
    print("âš ï¸ Error de UTF-8, intentando con latin1...")
    loader = CSVLoader(csv_file, encoding='latin1')
    documents = loader.load()
    print(f"âœ… Total de documentos en CSV: {len(documents)}")

# ğŸ¯ OPTIMIZACIÃ“N EXTREMA PARA S0: Solo muestra muy pequeÃ±a
MAX_DOCS = 10  # Solo 10 documentos para tier S0
print(f"ğŸ”¥ TIER S0 DETECTADO: Procesando solo {MAX_DOCS} documentos de {len(documents)}")
print("ğŸ“Š LÃ­mites S0: 20 RPM (~0.33 requests/second)")
print("â° Esto tomarÃ¡ aproximadamente 3-5 minutos con delays seguros")

if len(documents) > MAX_DOCS:
    documents = documents[:MAX_DOCS]

print("âœ‚ï¸ Dividiendo documentos...")
text_splitter = CharacterTextSplitter(chunk_size=800, chunk_overlap=0)  # Chunks mÃ¡s pequeÃ±os
docs = text_splitter.split_documents(documents)
print(f"âœ… Procesando {len(docs)} chunks")

print("ğŸš€ Creando Ã­ndice - MODO SÃšPER CONSERVADOR...")

# ğŸ›¡ï¸ ESTRATEGIA ULTRA CONSERVADORA PARA S0
REQUEST_DELAY = 4.0  # 4 segundos entre requests (muy conservador)
BATCH_SIZE = 1       # 1 documento por vez
total_requests = len(docs)

print(f"â° Tiempo estimado: {total_requests * REQUEST_DELAY / 60:.1f} minutos")
print("ğŸ”„ Procesando documento por documento...")

successful_docs = 0
failed_docs = 0

try:
    for i, doc in enumerate(docs):
        doc_num = i + 1
        print(f"ğŸ“¦ Procesando documento {doc_num}/{len(docs)}...")
        
        try:
            # Agregar UN documento por vez
            acs.add_documents(documents=[doc])
            successful_docs += 1
            print(f"âœ… Documento {doc_num} completado")
            
            # Delay fijo entre cada request
            if doc_num < len(docs):  # No delay despuÃ©s del Ãºltimo
                print(f"â³ Esperando {REQUEST_DELAY}s (rate limit S0)...")
                time.sleep(REQUEST_DELAY)
                
        except Exception as doc_error:
            failed_docs += 1
            print(f"âš ï¸ Error en documento {doc_num}: {str(doc_error)[:100]}...")
            
            # Si hay rate limit, esperar mÃ¡s tiempo
            if "rate limit" in str(doc_error).lower() or "429" in str(doc_error):
                print("ğŸ›‘ Rate limit detectado. Esperando 60 segundos...")
                time.sleep(60)
            else:
                print("â³ Esperando 10 segundos antes de continuar...")
                time.sleep(10)
    
    print(f"\nğŸ‰ Proceso completado!")
    print(f"âœ… Documentos exitosos: {successful_docs}")
    print(f"âŒ Documentos fallidos: {failed_docs}")
    
except KeyboardInterrupt:
    print(f"\nâš ï¸ Proceso cancelado por usuario")
    print(f"âœ… Documentos procesados antes de cancelar: {successful_docs}")
except Exception as e:
    print(f"âŒ Error general: {e}")

# Solo probar bÃºsqueda si se procesÃ³ al menos 1 documento
if successful_docs > 0:
    print("\nğŸ” Probando bÃºsqueda...")
    try:
        results = acs.similarity_search_with_relevance_scores(
            query="best wine",
            k=1,
        )
        print(f"âœ… Encontrados {len(results)} resultados")
        if results:
            content = results[0][0].page_content[:100]
            relevance = results[0][1]
            print(f"ğŸ· Resultado: {content}...")
            print(f"ğŸ¯ Relevancia: {relevance:.3f}")
    except Exception as e:
        print(f"âš ï¸ Error en bÃºsqueda: {e}")

print(f"\nğŸ“Š Resumen final:")
print(f"   ğŸ¯ Documentos objetivo: {MAX_DOCS} (optimizado para S0)")
print(f"   âœ… Documentos indexados: {successful_docs}")
print(f"   ğŸ” Ãndice: {os.getenv('SEARCH_INDEX_NAME')}")
print(f"   ğŸŒ Servicio: {os.getenv('SEARCH_SERVICE_NAME')}")

if successful_docs > 0:
    print(f"\nğŸš€ Â¡Ãndice bÃ¡sico creado! Ya puedes:")
    print(f"   - Ejecutar tu aplicaciÃ³n FastAPI")
    print(f"   - Hacer deploy a Azure")
    print(f"   - Agregar mÃ¡s documentos despuÃ©s si necesitas")
else:
    print(f"\nâŒ No se creÃ³ el Ã­ndice. Revisa:")
    print(f"   - Que las keys de OpenAI sean correctas")
    print(f"   - Que el deployment 'demo-embedding' exista")
    print(f"   - Considera solicitar aumento de quota: https://aka.ms/oai/quotaincrease")